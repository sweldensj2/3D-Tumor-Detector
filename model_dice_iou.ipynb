{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f601bb0a-6cc1-4294-b942-051846ff751e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  Tesla T4\n",
      "Allocated Memory: 0.00 GB\n",
      "Cached Memory: 0.00 GB\n",
      "Total GPU Memory: 14.58 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import nibabel as nib\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "final_project_path = '/home/jws2215/e6691-2024spring-project-jwss-jws2215' # vm\n",
    "data_folder_path = os.path.join(final_project_path, 'BraTS2020')\n",
    "train_folder_path = os.path.join(data_folder_path, 'train')\n",
    "valid_folder_path = os.path.join(data_folder_path, 'valid')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU name: \", torch.cuda.get_device_name(0))\n",
    "    allocated_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    cached_memory = torch.cuda.memory_reserved() / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Cannot print memory usage.\")\n",
    "    device = torch.device('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec99092-bb30-46af-ba9c-75037df70f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_dictionary(folder_path):\n",
    "    data_dict = {}\n",
    "    subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    \n",
    "    for idx, subfolder in enumerate(subfolders):\n",
    "        abs_path = os.path.join(folder_path, subfolder)\n",
    "        data_dict[idx] = {'absolute_path': abs_path, 'folder_name': subfolder}\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "data_path_dictionary_valid = create_data_dictionary(valid_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6107f0cc-5915-4ba7-9333-23eafebd6427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## all data is stored in (240,240,155) \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path_dictionary):\n",
    "        self.data_path_dictionary = data_path_dictionary\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(len(self.annotations[\"images\"]))\n",
    "        return len(self.data_path_dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        folder_name = self.data_path_dictionary[idx][\"folder_name\"]\n",
    "        folder_path = self.data_path_dictionary[idx][\"absolute_path\"]\n",
    "        \n",
    "        seg_path = os.path.join(folder_path, folder_name + '_seg.nii')\n",
    "        t1_path = os.path.join(folder_path, folder_name + '_t1.nii')\n",
    "        t1ce_path = os.path.join(folder_path, folder_name + '_t1ce.nii')\n",
    "        t2_path = os.path.join(folder_path, folder_name + '_t2.nii')\n",
    "        flair_path = os.path.join(folder_path, folder_name + '_flair.nii')\n",
    "        \n",
    "        # Load .nii files as nparrays\n",
    "        seg_img = nib.load(seg_path).get_fdata()\n",
    "        \n",
    "        t1_img = nib.load(t1_path).get_fdata() #combine these ones\n",
    "        t1ce_img = nib.load(t1ce_path).get_fdata()#combine these ones\n",
    "        t2_img = nib.load(t2_path).get_fdata()#combine these ones\n",
    "        flair_img = nib.load(flair_path).get_fdata()#combine these ones\n",
    "        \n",
    "        # Combine the MRI scans into a single 4-channel image\n",
    "        combined_mri = np.stack([t1_img, t1ce_img, t2_img, flair_img], axis=0)  \n",
    "        \n",
    "        # Convert combined_mri and seg_img to torch tensors\n",
    "        combined_mri = torch.tensor(combined_mri, dtype=torch.int32)\n",
    "        seg_img = torch.tensor(seg_img, dtype=torch.int32)\n",
    "\n",
    "        \n",
    "        #convert to binary problem:\n",
    "        seg_img[seg_img != 0] = 1\n",
    "        \n",
    "        return combined_mri, seg_img\n",
    "\n",
    "val_dataset = ImageDataset(data_path_dictionary_valid)\n",
    "batch_size = 1 # remember each item in a batch actually contains 155 subbatches\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053f4a09-e84f-4d79-a3c9-accdb4bdc288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model UNet(\n",
      "  (encoder_conv1): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder_conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder_conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder_conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder_upconv1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder_conv1): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder_upconv2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder_conv2): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder_upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder_conv3): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder_upconv4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder_conv4): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (output_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from seg_models import UNet, UNetPaper\n",
    "    \n",
    "    \n",
    "# Define the number of classes\n",
    "num_output_classes = 1 \n",
    "num_input_channels = 4\n",
    "\n",
    "# Custom Models\n",
    "model = UNet(num_input_channels, num_output_classes)\n",
    "\n",
    "# Paper Models\n",
    "# model = UNetPaper(num_input_channels, num_output_classes)\n",
    "\n",
    "# Load the saved weights\n",
    "saved_models_path = os.path.join(final_project_path, 'saved_models')\n",
    "\n",
    "\n",
    "####### Change the name here #########\n",
    "saved_model_path = os.path.join(saved_models_path, 'train_unet1_bce_lr1e-5_20e')\n",
    "\n",
    "# Add the file name\n",
    "saved_weights_path = 'best_unet.pth'\n",
    "saved_weights_path = os.path.join(saved_model_path, saved_weights_path)\n",
    "saved_weights = torch.load(saved_weights_path)\n",
    "\n",
    "# Load the weights into the model\n",
    "model.load_state_dict(saved_weights)\n",
    "model = model.to(device)\n",
    "print(\"model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b573df-1ee1-417a-8d29-5e777bbd55dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define functions to calculate Dice coefficient and IoU\n",
    "\n",
    "def calculate_dice_coefficient(prediction, target):\n",
    "    # Calculate intersection and union\n",
    "    intersection = torch.sum(prediction * target)\n",
    "    union = torch.sum(prediction) + torch.sum(target)\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice_coefficient = (2. * intersection) / (union + 1e-6)  # Add a small value to avoid division by zero\n",
    "    \n",
    "    return dice_coefficient\n",
    "\n",
    "def calculate_iou(prediction, target):\n",
    "    # Calculate intersection and union\n",
    "    intersection = torch.sum(prediction * target)\n",
    "    union = torch.sum(prediction) + torch.sum(target) - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection / (union + 1e-6)  # Add a small value to avoid division by zero\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770d3f31-20db-448c-a72c-6abb7dc7c204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Num: 0\n",
      "Batch Num: 155\n",
      "Batch Num: 310\n",
      "Batch Num: 465\n",
      "Batch Num: 620\n",
      "Batch Num: 775\n",
      "Batch Num: 930\n",
      "Batch Num: 1085\n",
      "Batch Num: 1240\n",
      "Batch Num: 1395\n",
      "Batch Num: 1550\n",
      "Batch Num: 1705\n",
      "Batch Num: 1860\n",
      "Batch Num: 2015\n",
      "Batch Num: 2170\n",
      "Batch Num: 2325\n",
      "Batch Num: 2480\n",
      "Batch Num: 2635\n",
      "Batch Num: 2790\n",
      "Batch Num: 2945\n",
      "total_batches 3100\n",
      "Average Dice Coefficient: tensor(0.2889)\n",
      "Average IoU Score: tensor(0.2524)\n",
      "Average Accuracy: 0.9975052419354828\n",
      "Average Sensitivity (Recall): 0.29352666664076826\n",
      "Average Specificity: 0.9985677304300982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "\n",
    "model.eval()\n",
    "dice_coefficient = 0.0\n",
    "iou_score = 0.0\n",
    "accuracy = 0.0\n",
    "sensitivity = 0.0\n",
    "specificity = 0.0\n",
    "total_batches = 0\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for combined_mris, seg_imgs in val_loader:\n",
    "        print(\"Batch Num:\", total_batches)\n",
    "        for depth_idx in range(combined_mris.size(4)):\n",
    "            current_slice = combined_mris[:, :, :, :, depth_idx].to(device)\n",
    "            current_seg = seg_imgs[:, :, :, depth_idx].long()\n",
    "            current_seg_one_hot = current_seg.unsqueeze(1).float().to(device)\n",
    "\n",
    "            # Predict\n",
    "            outputs = model(current_slice.float())\n",
    "            binary_prediction = (outputs > threshold).squeeze().cpu().detach().to(torch.int)\n",
    "            # print(\"binary_prediction\", binary_prediction.shape)\n",
    "\n",
    "            # Calculate Dice and IoU scores for the current depth slice\n",
    "            current_seg_np = current_seg.cpu().detach().to(torch.int)\n",
    "            # print(\"current_seg_np\", current_seg_np.shape)\n",
    "            unique_values = torch.unique(binary_prediction)\n",
    "            # print(\"binary_prediction\", unique_values)\n",
    "            unique_values = torch.unique(current_seg_np)\n",
    "            # print(\"current_seg_np\", unique_values)\n",
    "            dice_coefficient += calculate_dice_coefficient(binary_prediction, current_seg_np)\n",
    "            iou_score += calculate_iou(binary_prediction, current_seg_np)\n",
    "            \n",
    "            # Assuming binary_prediction and current_seg_np are both binary tensors\n",
    "            binary_prediction_np = binary_prediction.cpu().numpy().flatten()\n",
    "            current_seg_np_flat = current_seg_np.cpu().numpy().flatten()\n",
    "\n",
    "            # Calculate Accuracy\n",
    "            accuracy += accuracy_score(current_seg_np_flat, binary_prediction_np)\n",
    "\n",
    "            # Calculate Sensitivity (Recall)\n",
    "            sensitivity += recall_score(current_seg_np_flat, binary_prediction_np, average='binary', pos_label=1, zero_division='warn')\n",
    "\n",
    "            # Calculate Specificity Specificity = TN / (TN + FP)\n",
    "            true_negatives = ((current_seg_np_flat == 0) & (binary_prediction_np == 0)).sum()\n",
    "            false_positives = ((current_seg_np_flat == 0) & (binary_prediction_np == 1)).sum()\n",
    "            # Check if the denominator is zero\n",
    "            if (true_negatives + false_positives) == 0:\n",
    "                specificity += 0.0  # Assign a default value when the denominator is zero\n",
    "            else:\n",
    "                specificity += true_negatives / (true_negatives + false_positives)\n",
    "            \n",
    "            total_batches += 1\n",
    "\n",
    "# Calculate average scores for the epoch\n",
    "print(\"total_batches\", total_batches)\n",
    "avg_dice_coefficient = dice_coefficient / total_batches\n",
    "avg_iou_score = iou_score / total_batches\n",
    "avg_accuracy = accuracy / total_batches\n",
    "avg_sensitivity = sensitivity / total_batches\n",
    "avg_specificity = specificity / total_batches\n",
    "\n",
    "print(\"Average Dice Coefficient:\", avg_dice_coefficient)\n",
    "print(\"Average IoU Score:\", avg_iou_score)\n",
    "print(\"Average Accuracy:\", avg_accuracy)\n",
    "print(\"Average Sensitivity (Recall):\", avg_sensitivity)\n",
    "print(\"Average Specificity:\", avg_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b5478-d6aa-4b9f-bb56-e6590e062a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
