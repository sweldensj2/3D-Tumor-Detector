{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4949554d-8289-4b80-a50d-87b21719fc1d",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "The goal here is to load in a model and evaluate its performance on a random valid 3d MRI scan. The goal is to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cdd4ff-adc8-43f1-9b23-3bf9659b0166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name:  Tesla T4\n",
      "Allocated Memory: 0.23 GB\n",
      "Cached Memory: 0.24 GB\n",
      "Total GPU Memory: 14.58 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import nibabel as nib\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "final_project_path = '/home/jws2215/e6691-2024spring-project-jwss-jws2215' # vm\n",
    "data_folder_path = os.path.join(final_project_path, 'BraTS2020')\n",
    "train_folder_path = os.path.join(data_folder_path, 'train')\n",
    "valid_folder_path = os.path.join(data_folder_path, 'valid')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU name: \", torch.cuda.get_device_name(0))\n",
    "    allocated_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    cached_memory = torch.cuda.memory_reserved() / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    print(f\"Allocated Memory: {allocated_memory:.2f} GB\")\n",
    "    print(f\"Cached Memory: {cached_memory:.2f} GB\")\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "    print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Cannot print memory usage.\")\n",
    "    device = torch.device('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e44565-4b06-4f99-a34f-4b4538324e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_dictionary(folder_path):\n",
    "    data_dict = {}\n",
    "    subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    \n",
    "    for idx, subfolder in enumerate(subfolders):\n",
    "        abs_path = os.path.join(folder_path, subfolder)\n",
    "        data_dict[idx] = {'absolute_path': abs_path, 'folder_name': subfolder}\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "data_path_dictionary_train = create_data_dictionary(train_folder_path)\n",
    "data_path_dictionary_valid = create_data_dictionary(valid_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5dc056-94bf-40f9-9172-89fff2703603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## all data is stored in (240,240,155) \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path_dictionary):\n",
    "        self.data_path_dictionary = data_path_dictionary\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(len(self.annotations[\"images\"]))\n",
    "        return len(self.data_path_dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        folder_name = self.data_path_dictionary[idx][\"folder_name\"]\n",
    "        folder_path = self.data_path_dictionary[idx][\"absolute_path\"]\n",
    "        \n",
    "        seg_path = os.path.join(folder_path, folder_name + '_seg.nii')\n",
    "        t1_path = os.path.join(folder_path, folder_name + '_t1.nii')\n",
    "        t1ce_path = os.path.join(folder_path, folder_name + '_t1ce.nii')\n",
    "        t2_path = os.path.join(folder_path, folder_name + '_t2.nii')\n",
    "        flair_path = os.path.join(folder_path, folder_name + '_flair.nii')\n",
    "        \n",
    "        # Load .nii files as nparrays\n",
    "        seg_img = nib.load(seg_path).get_fdata()\n",
    "        \n",
    "        t1_img = nib.load(t1_path).get_fdata() #combine these ones\n",
    "        t1ce_img = nib.load(t1ce_path).get_fdata()#combine these ones\n",
    "        t2_img = nib.load(t2_path).get_fdata()#combine these ones\n",
    "        flair_img = nib.load(flair_path).get_fdata()#combine these ones\n",
    "        \n",
    "        # Combine the MRI scans into a single 4-channel image\n",
    "        combined_mri = np.stack([t1_img, t1ce_img, t2_img, flair_img], axis=0)  \n",
    "        \n",
    "        # Convert combined_mri and seg_img to torch tensors\n",
    "        # combined_mri = torch.tensor(combined_mri, dtype=torch.float32)\n",
    "        # seg_img = torch.tensor(seg_img, dtype=torch.float32)\n",
    "        combined_mri = torch.tensor(combined_mri, dtype=torch.int32)\n",
    "        seg_img = torch.tensor(seg_img, dtype=torch.int32)\n",
    "\n",
    "        \n",
    "        #convert to binary problem:\n",
    "        seg_img[seg_img != 0] = 1\n",
    "        \n",
    "        return combined_mri, seg_img\n",
    "\n",
    "val_dataset = ImageDataset(data_path_dictionary_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430e9c6-3ff4-4725-a508-eb68416fdb54",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8340b5-c8db-42c5-8c45-53667ee85b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder (downsampling path)\n",
    "        self.encoder_conv1 = self.conv_block(in_channels, 64)\n",
    "        \n",
    "        self.encoder_conv2 = self.conv_block(64, 128)\n",
    "        \n",
    "        self.encoder_conv3 = self.conv_block(128, 256)\n",
    "        \n",
    "        self.encoder_conv4 = self.conv_block(256, 512)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "\n",
    "        # Decoder (upsampling path)\n",
    "        self.decoder_upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder_conv1 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.decoder_upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder_conv2 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.decoder_upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder_conv3 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.decoder_upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder_conv4 = self.conv_block(128, 64)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder_conv1(x)\n",
    "        enc2 = self.encoder_conv2(F.max_pool2d(enc1, kernel_size=2, stride=2))\n",
    "        enc3 = self.encoder_conv3(F.max_pool2d(enc2, kernel_size=2, stride=2))\n",
    "        enc4 = self.encoder_conv4(F.max_pool2d(enc3, kernel_size=2, stride=2))\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, kernel_size=2, stride=2))\n",
    "\n",
    "        # Decoder\n",
    "        dec1 = self.decoder_upconv1(bottleneck)\n",
    "        dec1 = self.decoder_conv1(torch.cat([enc4, dec1], dim=1))\n",
    "        \n",
    "        dec2 = self.decoder_upconv2(dec1)\n",
    "        dec2 = self.decoder_conv2(torch.cat([enc3, dec2], dim=1))\n",
    "        \n",
    "        dec3 = self.decoder_upconv3(dec2)\n",
    "        dec3 = self.decoder_conv3(torch.cat([enc2, dec3], dim=1))\n",
    "        \n",
    "        dec4 = self.decoder_upconv4(dec3)\n",
    "        dec4 = self.decoder_conv4(torch.cat([enc1, dec4], dim=1))\n",
    "\n",
    "        # Output layer\n",
    "        output = self.output_conv(dec4)\n",
    "\n",
    "        return torch.sigmoid(output)\n",
    "        # output = F.softmax(output, dim=1)\n",
    "        # return output\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    \n",
    "# Define the number of classes\n",
    "num_output_classes = 1 #normally should be 5\n",
    "num_input_channels = 4\n",
    "\n",
    "# Custom Models\n",
    "model = UNet(num_input_channels, num_output_classes)\n",
    "\n",
    "# Load the saved weights\n",
    "final_project_path \n",
    "saved_models_path = os.path.join(final_project_path, 'saved_models')\n",
    "\n",
    "####### Change the name here #########\n",
    "saved_model_path = os.path.join(saved_models_path, 'train_unet1_bce_lr1e-5_6e')\n",
    "\n",
    "# Add the file name\n",
    "saved_weights_path = 'last_unet.pth'\n",
    "saved_weights_path = os.path.join(saved_model_path, saved_weights_path)\n",
    "saved_weights = torch.load(saved_weights_path)\n",
    "\n",
    "# Load the weights into the model\n",
    "model.load_state_dict(saved_weights)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efb70b-8561-46f5-bc31-eb21d0475bbe",
   "metadata": {},
   "source": [
    "# Evaluation on a Valid Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5119b5-81f3-4a60-ab63-83feb52cf88d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_scan (tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.int32), tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "patient_number = 5 # range between 1-19\n",
    "\n",
    "patient_scan = val_dataset.__getitem__(patient_number)\n",
    "print(\"patient_scan\", patient_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb9d00-9b9a-4bda-9e92-7e66cf806e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
